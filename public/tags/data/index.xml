<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data on Michael Harper</title>
    <link>/tags/data/</link>
    <description>Recent content in Data on Michael Harper</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>m.harper@outlook.com (Michael Harper)</managingEditor>
    <webMaster>m.harper@outlook.com (Michael Harper)</webMaster>
    <copyright>(c) 2020 Copyright Michael Harper</copyright>
    <lastBuildDate>Tue, 24 Mar 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/data/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Creating Twitter Wordclouds in R</title>
      <link>/creating-twitter-wordclouds/</link>
      <pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate>
      <author>m.harper@outlook.com (Michael Harper)</author>
      <guid>/creating-twitter-wordclouds/</guid>
      <description>I recently finished my PhD, and my supervisor, Patrick James, always described me as a “data monster” in reference to how much I enjoyed playing with data. He was a massive influence throughout my PhD, so I felt it was only appropriate to get him a data-related gift when I finished. To this effect, I made him a wordcloud of all his tweet history!
This blog post explains how we can interact with Twitter data in R using the rtweet (Kearney 2018) package, and convert this raw data into pretty visualisations using the wordcloud2 (Lang 2018) package.</description>
    </item>
    
    <item>
      <title>Mapping UK Local Political Data</title>
      <link>/mapping-uk-local-political-data/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      <author>m.harper@outlook.com (Michael Harper)</author>
      <guid>/mapping-uk-local-political-data/</guid>
      <description>knitr::opts_chunk$set(eval=FALSE) For my PhD research, I needed to collect local political data for the UK. This article documents the data sources and procedure used to create a suitable dataset for my analysis. This provides a technical overview of the data. The R code used to create the analysis is available through GitHub here.
Setup R was used to run the analysis. The code uses a number of packages to process the data:</description>
    </item>
    
  </channel>
</rss>